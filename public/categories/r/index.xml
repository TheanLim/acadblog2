<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R on Thean C. Lim</title>
    <link>/categories/r/</link>
    <description>Recent content in R on Thean C. Lim</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018 Thean Cheat Lim</copyright>
    <lastBuildDate>Sat, 30 Jun 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/r/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Exploratory Data Analysis (EDA)</title>
      <link>/readings/exploratory-data-analysis/</link>
      <pubDate>Sat, 30 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/readings/exploratory-data-analysis/</guid>
      <description>VariationVisualizationsCategorical Variable – Bar chart with geom_barContinuous VariableHistogram with geom_histogramOverlapping Histograms using geom_freqpolyTypical valuesUnusual ValuesZoom in into plot without resetting xlim and ylim with coord_cartesianMissing ValuesRowwise Deletion vs Replacing with NAsSuppressing ggplot2 NAs removal warnings with na.rm = TRUEComparing missing vs non-missing values by creating new variable using is.na()CovariationA Categorical and Continuous VariableDensity Plot with geom_freqpolyLarge DatasetLetter-value plot (for large dataset|instead of boxplot) using geom_lvViolin plot (to show distributions) using geom_violinSmall DatasetBoxplot (for small dataset) using geom_boxplotReorder the levels of categorical variables using reorder()Horizontal boxplot using coord_flip or geom_boxplothJitter points using geom_jitterJitter + Violin plot using geom_quasirandomOffsetting (sideway) the violin plot using geom_beeswarmTwo Categorical VariablesBubble Chart with geom_countHeatmap Plotting with geom_tileTwo Continuous VariablesScatterplot using geom_pointLarge dataset problems and solutionsUsing alpha aesthethics in geom_pointUsing BinsUsing bin with geom_bin2d()Using bin with geom_hex()Bin by breaking continuous into categorical variableUsing cutwidth to binUsing cutnumber to binPatterns and Models** This post is heavily based on R for Data Science.</description>
    </item>
    
    <item>
      <title>Clustering: k-means, k-means &#43;&#43; and gganimate</title>
      <link>/post/clustering-k-means-k-means-and-gganimate/</link>
      <pubDate>Thu, 19 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/clustering-k-means-k-means-and-gganimate/</guid>
      <description>IntroductionThe ProblemK-means ClusteringImplementationData Simulation and VisualizationK-means ++ ClusteringImplementationsVisualizationChoosing K - the Elbow MethodNext StepReferencesIntroductionClustering methods attempt to group object based on the similarities of the objects. For example, one can group their customers into several clusters so that one can aim a specific way of marketing to each type of customers.
Since there is no preexisting group labels for each cluster, we can never know the accuracy of clustering methods unless using a simulated data.</description>
    </item>
    
    <item>
      <title>gganimate: Animations with ggplot2</title>
      <link>/post/gganimate-animations-with-ggplot2/</link>
      <pubDate>Thu, 19 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/gganimate-animations-with-ggplot2/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Cross Validation Function for Classifier</title>
      <link>/post/cross-validation-function-for-classifier/</link>
      <pubDate>Mon, 16 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/cross-validation-function-for-classifier/</guid>
      <description>IntroductionSelf-defined functionscvclassifierArguments and ValuesImplementationsclasspred.cvArguments and ValuesImplementationsSimulation, Errors and KNN BoundariesExample 1Simulate DataTraining and Testing ErrorsCross ValidationDecision BoundariesExample 2Simulate DataTraining and Testing ErrorsCross ValidationDecision BoundariesNext StepsIntroductionAs mentioned in the previous post, the natural step after creating a KNN classifier is to define another function that can be used for cross-validation (CV).</description>
    </item>
    
    <item>
      <title>Data Visualization with ggplot2</title>
      <link>/readings/data-visualization-with-ggplot2/</link>
      <pubDate>Sun, 15 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/readings/data-visualization-with-ggplot2/</guid>
      <description></description>
    </item>
    
    <item>
      <title>K Nearest Neighbour Classsifier (self-written function)</title>
      <link>/post/k-nearest-neighbour-classifier-self-written-function/</link>
      <pubDate>Sun, 15 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/k-nearest-neighbour-classifier-self-written-function/</guid>
      <description>IntroductionSelf-defined KNN ClassifierSimulation, errors and KNN BoundarySimulate dataTraining and Testing ErrorsDecision boundariesNext stepsIntroductionThe K-nearest neighbors (KNN) classifier works by indentifying \(K\) (a positive integer) training data points that are closest (defined by Euclidean distance) to a test observation \(x_0\) and calculate the conditional probability of \(x_0\) belongs to class \(j\). The conditional probability equals to the fraction of the \(K\) training data points that belongs to class \(j\).</description>
    </item>
    
    <item>
      <title>Linear Regression Simulation Study</title>
      <link>/post/linear-regression-simulation-study-plotly-theanlim/</link>
      <pubDate>Sat, 14 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/linear-regression-simulation-study-plotly-theanlim/</guid>
      <description>TheoriesModel AssumptionsOrdinary Least Square Estimator (OLS) of \(\beta\)Estimator of \(\sigma^2\)SimulationVisualize data pointsEstimating \(\beta\) and \(\epsilon\)Visualize fitted planeIn general, linear regression is a linear approach of modelling the relationship of a numerical response (dependent) variable and one or more explanatory (independent) variables.
TheoriesModel AssumptionsLet:
\(y_i \in \mathbb{R}^n\) as the measured response for the \(i\)th subject.</description>
    </item>
    
    <item>
      <title>Term Deposit Subscription Prediction</title>
      <link>/project/term-deposit-subscription-prediction/</link>
      <pubDate>Sat, 14 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/project/term-deposit-subscription-prediction/</guid>
      <description>IntroductionData Manipulation and Descriptive AnalysisMissing data, NAsImbalance ClassificationCorrelationDistributionsModel FittingTraining and Testing DataDecision Tree fittingCross-validation, Tree-pruning and Training ErrorsTesting Error and Prediction AccuracyInterpretationBusiness StrategyNextIntroductionThe dataset used in this project is obtained fromm the UCI Machine Learning Repository. This dataset is related to direct telemarketing campaigns of a Portuguese banking institution, collected from 2008 to 2013.</description>
    </item>
    
    <item>
      <title>Image Compression with Principal Component Analysis</title>
      <link>/project/image-compression-with-principal-component-analysis/</link>
      <pubDate>Fri, 13 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/project/image-compression-with-principal-component-analysis/</guid>
      <description>Loading pictures and standardizing the sizesThe tour Image.PCAScree Plot and Cumulative Variation PlotImage ReconstructionImage Size CompressionThe no_tour ImageThe new Image.SummaryThe following images are taken from DesignCrowd.
This first image is an image with tourists ( I call it as tour) while the second one has no tourist – no_tour.
This is another new image that is different from the above two.</description>
    </item>
    
    <item>
      <title>Hello World: Blogging using Rmd</title>
      <link>/post/hello-world-blogging-using-rmd/</link>
      <pubDate>Thu, 12 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/hello-world-blogging-using-rmd/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>